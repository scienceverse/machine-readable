---
title: "Extended Example Machine Readable Hypothesis"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(scienceverse)
```

One goal of scienceverse is to automate the evaluation of predictions. A researcher specifies the prediction in the preregistration, collects the data, and scienceverse can then take the preregistration file and the data and automatically evaluate whether the predictions were confirmed or not.

The demo below follows the example from: 

Lakens, D., & DeBruine, L. M. (2020, January 27). Improving Transparency, Falsifiability, and Rigour by Making Hypothesis Tests Machine Readable. <https://doi.org/10.31234/osf.io/5xcda>

### Set up the study

Set up the study with a name and any additional info you want to add.

```{r}
study <- study(name = "Kinship and Prosocial Behaviour",
               abstract = "A reanalysis of data from DeBruine (2002) Facial Resemblance Enhances Trust, PRSLB.")
```

### Authors

Add each author in the following format. Use the function `credit_roles()` to see a list of the roles and their descriptions. Use `credit_roles("name")` or `credit_roles("abbr")` to just see their names or abbreviations. You can also add any further info, like an orcid or email address.

```{r}
study <- add_author(study, 
                    orcid = "0000-0002-7523-5539",
                    surname = "DeBruine",
                    given = "Lisa M.",
                    roles = c("con", "dat", "sof", "dra", "edi"),
                    email = "lisa.debruine@glasgow.ac.uk") %>%
         add_author(orcid = "0000-0002-0247-239X",
                    surname = "Lakens",
                    given = "DaniÃ«l",
                    roles = c("con", "ana", "dra", "edi"))
```

### Hypotheses

Now add a hypothesis with a verbal description. You can add more than one hypothesis, but this demo study only has one.

```{r}
study <- add_hypothesis(study, id = "self_pref",
                        description = "Cues of kinship will increase prosocial behaviour. Cues of kinship will be manipulated by morphed facial self-resemblance. Prosocial behaviour will be measured by responses in the trust game. The prediction is that the number of trusting AND/OR reciprocating moves will be greater to self morphs than to other morphs.")
```

### Analyses

Add all relevant analyses for testing this hypothesis in the order that they should be run. Do any data prep first. Each analysis needs an `id` for reference in the criteria later. The `code` can be R code (wrap it in {} if you need more than one line) or the file path for a .R file. You can also add other information about your analysis, such as the software it's running on. 

```{r}
study <- add_analysis(study,
                      id = "trust",
                      code = t.test(kin$trust_self, 
                                    kin$trust_other, 
                                    paired = TRUE, 
                                    conf.level = 0.975), 
                      software = R.version.string) %>%
         add_analysis(id = "recip",
                      code = t.test(kin$recip_self,
                                    kin$recip_other,
                                    paired = TRUE,
                                    conf.level = 0.975), 
                      software = R.version.string)
```

### Auxillary Assumptions

You can also test auxillary assumptions and set up more complicated decision rules for evaluation. Here, we'll test whether the resulting data are normally distributed and use an alternative statistical test if they are not.

```{r}
# test normality of the 4 dvs
study <- add_analysis(study, id = "norm",
  code = {
    ts <- shapiro.test(kin$trust_self)$p.value
    to <- shapiro.test(kin$trust_other)$p.value
    rs <- shapiro.test(kin$recip_self)$p.value
    ro <- shapiro.test(kin$recip_other)$p.value
  }, 
  return = c("ts", "to", "rs", "ro"),
  software = R.version.string)

study <- add_analysis(study,
                      id = "trust_wilcox",
                      code = wilcox.test(kin$trust_self, 
                                    kin$trust_other, 
                                    paired = TRUE, 
                                    conf.level = 0.975,
                                    conf.int = TRUE), 
                      software = R.version.string) %>%
         add_analysis(id = "recip_wilcox",
                      code = wilcox.test(kin$recip_self,
                                    kin$recip_other,
                                    paired = TRUE,
                                    conf.level = 0.975,
                                    conf.int = TRUE), 
                      software = R.version.string)
```




### Criteria

Next, add the criteria you will need to check to corroborate or falsify each hypothesis. Each criterion needs a unique `id` so you can reference it next in the evaluation. Then, specify the `analysis_id` where you'll look for the result. For example, the analysis `trust` returns a list from the function `t.test`, which includes a value for `conf.int`. To see if the first number in this vector is larger than 0, set `result` to "conf.int[1]", `operator` to ">" , and `comparator` to $0$. The options for `operator` are ">", "<", "=", and "!=".

```{r}
study <- study %>%
  add_criterion(id = "t_lo",
                analysis_id = "trust",
                result = "conf.int[1]",
                operator = ">",
                comparator = 0) %>%
  add_criterion(id = "t_hi",
                analysis_id = "trust",
                result = "conf.int[2]",
                operator = ">",
                comparator = 0.2) %>%
  add_criterion(id = "r_lo",
                analysis_id = "recip",
                result = "conf.int[1]",
                operator = ">",
                comparator = 0) %>%
  add_criterion(id = "r_hi",
                analysis_id = "recip",
                result = "conf.int[2]",
                operator = ">",
                comparator = 0.2) %>%
  add_criterion(id = "ts_norm",
                analysis_id = "norm",
                result = "ts",
                operator = ">",
                comparator = 0.05) %>%
  add_criterion(id = "to_norm",
                analysis_id = "norm",
                result = "to",
                operator = ">",
                comparator = 0.05) %>%
  add_criterion(id = "rs_norm",
                analysis_id = "norm",
                result = "rs",
                operator = ">",
                comparator = 0.05) %>%
  add_criterion(id = "ro_norm",
                analysis_id = "norm",
                result = "ro",
                operator = ">",
                comparator = 0.05)%>%
  add_criterion(id = "t_lo_w",
                analysis_id = "trust_wilcox",
                result = "conf.int[1]",
                operator = ">",
                comparator = 0) %>%
  add_criterion(id = "t_hi_w",
                analysis_id = "trust_wilcox",
                result = "conf.int[2]",
                operator = ">",
                comparator = 0.2) %>%
  add_criterion(id = "r_lo_w",
                analysis_id = "recip_wilcox",
                result = "conf.int[1]",
                operator = ">",
                comparator = 0) %>%
  add_criterion(id = "r_hi_w",
                analysis_id = "recip_wilcox",
                result = "conf.int[2]",
                operator = ">",
                comparator = 0.2)
  
```

### Evaluation

Add evaluation criteria for corroboration and falsification. Include a verbal `description` and a logical `evaluation` that references the criterion `id`s above.

```{r}
study <- add_eval(study, "corroboration",
                  description = "The hypothesis is corroborated if the 97.5% CI lower bound is greater than 0 and the 97.5% CI upper bound is greater than 0.2 (the SESOI) for either the trust or reciprocation moves. Use t.test if the data are normally distributed, or Wilcox test otherwise.",
                  evaluation = "
                  (ts_norm & to_norm & t_lo & t_hi) | 
                  (!(ts_norm & to_norm) & t_lo_w & t_hi_w) | 
                  (rs_norm & ro_norm & r_lo & r_hi) | 
                  (!(rs_norm & ro_norm) & r_lo_w & r_hi_w)") %>%
         add_eval("falsification",
                  description = "The hypothesis is falsified if the 97.5% CI upper bound is smaller than 0.2 (the SESOI) for both trust and reciprocation. Use t.test if the data are normally distributed, or Wilcox test otherwise.",
                  evaluation = "
                  ( (ts_norm & to_norm & !t_hi) |
                    (!(ts_norm & to_norm) & !t_hi_w) ) & 
                  ( (rs_norm & ro_norm & !r_hi) |
                    (!(rs_norm & ro_norm) & !r_hi_w) )")
```


### Save in machine-readable format

At this point, you can save your study to a machine-readable JSON-formatted file.

```{r}
study_save(study, "ext_prereg.json", format = "json")
```

### Save in human-readable format

You can also export a human-readable pre-registration using the built-in "prereg" template.

```{r}
study_save(study, "ext_prereg.html", format = "prereg")
```

### Data

The `id` you give the data can be used in the analysis code to refer to this dataset. The `data` argument can be a data frame or a file path to a data file or a PsychDS-formatted codebook. You can optionally add column parameters such as descriptions with the argument `vardesc` and other dataset parameters as additional arguments.

```{r}

kin_data <- data.frame(
  trust_self  = c(1,2,2,1,1,1,1,1,2,0,2,0,1,2,2,3,2,2,1,1,2,0,0,1),
  trust_other = c(1,2,2,0,1,0,0,0,1,0,1,0,1,1,1,0,1,2,2,0,0,0,2,1),
  recip_self  = c(0,1,3,2,1,1,1,3,3,2,3,1,1,2,3,3,3,1,1,1,3,0,3,1),
  recip_other = c(1,1,2,2,3,2,1,3,3,1,3,0,1,3,3,3,3,0,3,0,1,0,3,2)
)

desc <- list(
  description = list(
    trust_self  = "Number of trusting moves towards self-morphs",
    trust_other = "Number of trusting moves towards self-morphs",
    recip_self  = "Number of reciprocating moves towards other-morphs",
    recip_other = "Number of reciprocating moves towards other-morphs"
  ),
  type = rep("int", 4) # all variables are integer types
)

study <- add_data(study, id = "kin", 
                  data = kin_data, 
                  vardesc = desc, 
                  url = "https://osf.io/ewfhs/")

```

### Run Analyses

When you run `study_analyse`, the data are loaded as their `id` names and the analyses are run in order. The evaluation of each criterion and hypothesis is printed as a message.

```{r, warning=FALSE}
study <- study_analyse(study)
```


### Save

At this point, you can save the post-registration version of your study to a JSON-formatted file and also export a human-readable post-registration report.

```{r}
study_save(study, "ext_postreg.json", "json")
study_save(study, "ext_postreg.html", "postreg")
```

### Reload

You can reload and edit your study by loading the .json file with the study() function.

```{r}
study2 <- study("ext_postreg.json")

study2 # displays a summary
```

### Edit analyses

If you want to explore how the results change if you change criteria or analyses, you can use the functions `update_analysis` or `update_criteria`.

For example, we can change the analyses to use 95% CIs instead of 97.5% CIs. Make sure to re-analyse after changing data, analyses or criteria (this doesn't happen automatically because some analyses can take a very long time).


```{r, warning=FALSE}
study2 <- study2 %>%
  update_analysis(id = "trust",
                  code = t.test(kin$trust_self, 
                                kin$trust_other, 
                                paired = TRUE, 
                                conf.level = 0.95)) %>%
  update_analysis(id = "recip",
                  code = t.test(kin$recip_self,
                                kin$recip_other,
                                paired = TRUE,
                                conf.level = 0.95)) %>%
  update_analysis(id = "trust_wilcox",
                  code = wilcox.test(kin$trust_self, 
                                     kin$trust_other, 
                                     paired = TRUE, 
                                     conf.level = 0.95,
                                     conf.int = TRUE)) %>%
  update_analysis(id = "recip_wilcox",
                  code = wilcox.test(kin$recip_self,
                                     kin$recip_other,
                                     paired = TRUE,
                                     conf.level = 0.95,
                                     conf.int = TRUE)) %>%
  study_analyse()

```

